[
  {
    "id": "234610606489461760",
    "type": "industryBusiness",
    "url": "http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=2649506596&idx=1&sn=3b33e8cf3da300c37a611e52bc854d62&chksm=838e533a42558e13da55813775cd24d8e812984553b47856681a91441d032456eef857efab92&scene=0&xtrack=1#rd",
    "title": "AI Next播客 | 对话韦福如：人工智能的下一代前沿——科学规模化与学习范式的革命",
    "description": "微软首席科学家韦福如探讨AI核心前沿：科学规模化、学习范式革命、持续学习、多模态统一及智能体发展。",
    "published_date": "2026-01-15T09:00:00.596Z",
    "authors": "",
    "source": "微软研究院",
    "score": 85,
    "category": "AI资讯",
    "tags": [
      "科学规模化",
      "学习范式",
      "持续学习",
      "多模态模型",
      "智能体"
    ],
    "details": {
      "content_html": "AI Next 播客 | 对话韦福如：人工智能的下一代前沿——科学规模化与学习范式的革命\n编辑部\n编辑部\n微软亚洲研究院\n <此处有图 node_id_453> <此处有图 node_id_454> <此处有图 node_id_455>\n《AI Next》是微软亚洲研究院推出的一档利用 AI 技术制作的播客，内容聚焦 AI 前沿技术、科研趋势与社会影响。第一季主要围绕当今智能发展的核心议题，探索前沿趋势。\n在《AI Next》第四期中，我们邀请到微软亚洲研究院首席科学家韦福如，从第一性原理出发，与大家探讨当前 AI 发展中最核心、具有争议的前沿问题。为何 Scaling 仍是 AI 的第一性原理，但必须走向“科学规模化”；为什么 AI 已能很好地解决 In-Distribution 问题，却仍未真正学会“学习本身”；为何下一次决定性跃迁，来自学习范式而非单纯工程优化。从基础研究到产业化路径，让我们共同开启这场关于 AI 下一代范式迁移的深度对话。\n欢迎大家订阅、收听、分享！\n <此处有图 node_id_489> <此处有图 node_id_490>\n\n\n作为一档由 AI 合成的播客栏目，《AI Next》播客音频和宣传视频背后包含微软亚洲研究院在合成 AI 领域的三项关键技术：\nVibeVoice 具备自然、富有表现力的语音合成能力，能够为最多4位说话者合成长达90分钟的高质量对话语音，为用户带来更灵动的声音互动感受。 VASA\n可将静态肖像与音频信号结合，合成情感逼真且拥有细腻面部表情的说话头像，为内容创作及辅助教育提供了全新的呈现方式。TRELLIS 则是一个 3D 物品生成模型，能依据文本提示或图片信息构建相应的 3D 效果，让复杂的概念设计可以在立体空间中被“看见”。目前，VASA 和 TRELLIS 技术可在微软的 Copilot 产品中体验，VibeVoice 也已在 Hugging Face 上开源。三项技术的加持将为内容创造者和听众带来 AI 技术演进的真实体验。\n嘉宾介绍\n韦福如博士\n韦福如博士现任微软亚洲研究院首席科学家、微软杰出科学家，领导团队从事基础模型、自然语言处理、语音处理和多模态人工智能等领域的研究。近年来，他还致力于领导和推进通用人工智能的基础研究和创新。\n韦福如博士和团队在基础模型和通用人工智能领域发表和开源了一系列开创性、有影响力的论文和模型，例如 UniLM, MiniLM, LayoutLM, BEiT, VALL-E, YOCO, BitNet, Differential Transformer, LatentLM, MiniLLM, RPT, VibeVoice 等等。韦福如博士在顶级会议和期刊上发表了200多篇研究论文（被引用超过70,000次，H-Index 120）。\n韦福如博士分别于2004年和2009年获得武汉大学学士学位和博士学位。2017年，他因对自然语言处理的贡献入选《麻省理工技术评论》中国35岁以下创新者年度榜单（MIT TR35 China），2018年入选中国 AI 英雄风云榜技术新锐奖榜单。2019年“统一自然语言预训练模型与机器阅读理解”入选世界互联网领先科技成果奖，2024年 LayoutLM 荣获国际基础科学大会前沿科学奖。2020年入选北京市劳动模范。\n\n<此处有图 node_id_576>\n观点速读\n参考韦福如博士日常的阅读与信息梳理方式，在本篇正文开始之前，我们将播客中韦福如博士超高密度的金句进行了汇总，希望可以帮助大家快速了解本次对话的核心观点。\n“规模化（Scaling）是 AI 的第一性原理，但我们需要的是科学规模化。本质上所有的创新，不管是模型架构、学习范式、数据、系统还是硬件的创新，都是为了更有效和更高效的规模化。规模化和创新两者一起构成驱动AI前进的双轮，缺一不可。”\n“AI 基本可以很好地解决 In-Distribution 问题，也就是如果我们可以把一个问题转化成一个 In-Distribution 的问题，基本就解决了，也有一定的组合泛化能力，但是更加通用的泛化能力还需要新的突破。”\n“刷榜和刷题有本质区别，刷榜是对着评测结果直接过拟合，刷题是对着目标针对性优化。刷榜或者刷题本身不重要，但总得有个评估标准。关键是不能对着 benchmark 专门去做。真正难的是把它当成有效的评估，尤其是看技术和能力能不能泛化、迁移。”\n“现在的 AI，大部分已经变成了工程问题，但是未来起决定性作用却是非常少的几个关键研究问题的突破，需要有类似 Transformer，GPT-3，o1 这样里程碑式的下一个范式迁移。”\n“大脑是 AI 很好的镜像和北极星，虽然实现路径会不一样，但是神经科学的很多发现在目标和方向上为 AI 提供了很重要和可类比的参考，比如神经可塑性（neuroplasticity）和预测性处理（predictive processing）都是接下来 AI 最重要的研究课题和目标。”\n“我们需要的是有必要性的创新，否则就是在创造新的问题，而不是解决要解决的问题。什么叫必要性？这要满足两个条件，一个条件就是说你要能做以前做不了的事情，但是有一个前提，你以前能做的也要能做。这是一个帕雷托提升，一个向下兼容。第二个的话就是你需要有这种量级的效能提升，如果只是提升1%、2%，从极致工程的角度通过很多的这种提升拿到复利的效应是有意义的，但是从科学范式的角度看可能意义不够大。”\n“AI 模型的三块基石，模型架构、学习范式，以及规模化，模型架构和规模化还会不断迭代和优化，但是接下来最大的机会和必要性是学习范式的革命。”\n“AI 什么东西都学得很好，但唯一就是没有学会学习本身。而人最厉害的地方是具备了学习这个能力。学会学习是AI接下来最重要的课题。”\n“在线学习和持续学习是接下来 AI 最重要的基础能力，现在问题和目标已经是共识了，但技术路径还存在非共识区间。”\n“原生全模态模型和思考是推进智能上界的一个方向，而且从 AI 和人的终极交互界面和形式来说，也是构建下一代原生 AI 产品的关键技术。”\n“Natural Context = Omnimodality + Memory + Any Context，Everything is Context，Everything as Context, 就是说 AI 能在任意上下文，或者说任意场景中有效利用相关信息，包括各种当前环境、各种模态的输入和历史，或称之为记忆的信息，根据当前场景作为自然的提示词，甚至能主动感知到需求。这将是未来AI的终极 UX 和交互范式。”\n“1比特是个很重要的机会。现在的 AI 计算都是基于矩阵运算的，它的基础就是浮点数的矩阵乘法。但如果你做到了1比特，那就跟其他低比特不一样了，它只有加法，从能源消耗的角度讲，它有天然的优势，1比特有机会从本质上去解决问题。这也是接下来模型架构、系统和硬件协同创新的大机会。”\n“AI 的一大趋势是大融合和大统一，可以预见到世界模型最后也会和大语言模型是同一个模型。”\n“AI 的落地和产业化的路径，其实也很清晰，就是通过智能体以及以智能体为基础的智能组织来提升和拓展人类社会的生产力从而创造经济和社会价值。”\n“关于 Coding Agent 和 Computer-Use Agent 的路线之争。我们认为 Coding Agent 应该是更可能的路径，这也再次印证了莫拉维克悖论 – 写代码对于人类来说可能很难，但是对 AI 来说很简单，而使用电脑对人类来说很简单，但对 AI 可能很难。”\n“Coding Agent 的通用性其实被大大低估了，本质上，code 才是 AI 的原生语言。”\n“本质上，AI 的进步其实基本是和找到正确的 Scaling 维度高度重合，也就是怎么有效和高效地把计算（电能）转化为智能，除了目前已有的通用规模法则（Scaling Law），智能体规模法则（Agentic Scaling Law）和经验法则（Experience Law）会成为接下来 AI 发展的关键推动基础。”\n“AI 研究和创新的三个关键词：品味，终局思维与第一性原理。”\n“研究、模型、产品是同一个问题的一体三面，最好的研究会产生最好的模型，有了最好的模型才会有真正革命性的产品，都需要对智能边界的提前感知、创造和使用，以及对技术和产品品味的极致追求。”\n“还有一些更加基础的科学问题，比如 In-Weight Learning 和 In-Context Learning 的内在联系和统一。某种意义上，我们进入了新的大航海时代，需要去探索剩下的最后少数几个‘新大陆’，或者说还有非常关键的可能1-2个单点的范式迁移式技术突破，这也是这个时代的 AI 研究人员和研究团队的真正目标和梦想。”\n如下是《AI Next》第四期播客内容的文字整理：\n主持人：大家好，欢迎收听《AI Next》第一季第四期。\n现在 AI 发展的节奏太快了，请问如何保持对最新研究和技术的跟进速度？\n韦福如：\n持续关注最新动态是基础，但更关键的是要有自己的判断，或者说一种“品味”。我看研究时是带着明确观点的，甚至可以说是有偏见的，因为你必须要有自己的思维模型。一方面，我会重点关注自己真正关心的问题，很多都和我们正在做的研究直接相关；另一方面，也会长期跟踪一些前沿实验室、特定科研人员和团队，看他们在解决什么问题、做到什么程度。当然，也会保持一定的开放性，看一些有意思的工作，但不会什么都看。\n我的阅读渠道其实很分散，包括 arXiv、社交平台以及自媒体等。同事之间也会互相推荐论文。最重要的是要找到那些和我们关心的问题本质上相关，但是形式上未必直接相关的好工作，这需要持续关注，也需要一些“缘分”。\n图片\n规模化是否真的见顶了？\n主持人：最近关于规模红利减弱的讨论越来越多。作为一线研究员，你是否观察到了性能提升趋缓的信号？\n韦福如：\n首先，规模化（Scaling）是 AI 的第一性原理，也就是如何把计算、把电能高效地转化为智能。但我们需要“科学规模化”，不仅要做大，还要在正确的维度上做大。所有创新，无论是模型架构、学习范式、数据、系统还是硬件，归根结底都是为了更有效、更高效地规模化。规模化和创新是一对驱动 AI 前进的双轮，缺一不可。\n至于规模红利是不是在减弱，我觉得所有技术本身都遵循 S 曲线，这是客观规律。当走到曲线的平缓区，投入和产出的边际收益自然会下降。我认为，规模依然是基础，但只靠扩展规模显然不够了。在当前阶段，限制不完全来自架构，而更多来自数据和评估方式。当算力已经足够强、数据增长速度又明显跟不上时，性能提升趋缓是必然的。\n另外，由于现在的模型能力非常强，很多传统评测已经失效了，于是大家开始尝试更难的 benchmark，比如做数学题。然而一旦 benchmark 被固定，优化到一定程度后，规模带来的收益就会变小。\n换言之，AI 基本上可以很好地解决 In-Distribution（同分布）问题了。只要能够把问题转化为分布内问题，那么它基本就能解决。\n图片\n刷榜的意义是什么？\n主 持人：那刷榜还有意义吗？\n韦福如：\n要正确地刷榜。刷榜和刷题是两回事。刷榜往往是对评测结果的直接过拟合；而刷题是围绕目标做针对性优化。\n关键在于是否把 benchmark 当作有效的评估工具，去验证技术的泛化和迁移能力。比如数学模型，如果它只会做数学题，那价值有限；但如果它通过解题学会了复杂的思考过程，并能迁移到其他任务上，那就很有意义。所以最终还是要把结果和技术放在一起看，只有技术突破支撑的结果才可靠。\n图片\nTransformer到底是不是瓶颈？数据荒背后，真正稀缺的是什么？\n主 持人：Transformer 架构本身是否也已成为瓶颈？数据方面是不是也开始面临挑战？\n韦福如：\n我不认为当前的放缓主要是 Transformer 的问题。限制更多来自输入和输出，也就是数据和评估。当然，Transformer 在超大规模扩展时确实有复杂度、长序列等挑战，但目前还没有证据表明它是导致规模红利下降的主要原因。\n数据确实跟不上 AI 的发展速度。这其实是个“面多了加水，水多了加面”的问题。最初算力不足时，互联网数据显得很多；但当 GPU 算力提升了百万倍，数据反而不够用了。数据的生成速度远远慢于算力的增长，这是客观规律。但问题不只是数量，还有利用方式。\nNext token prediction 限制了数据的利用效率。人类在生成文本时，记录的只是结果，而不是思考过程，这些中间的“暗知识”是缺失的。这也是我们为什么做 RPT（强化预训练）和 TPT（思考增强预训练）的原因，希望把思考过程引入预训练阶段，从而提升数据的利用效率。虽然这类方法目前还很难验证，但它们可能在 S 曲线进入平缓区时发挥巨大作用。\n主持人：尽管规模收益在递减，但仍有人认为，只要算力和数据足够，Scaling Law 依然成立。如果继续在现有的 Transformer 架构上扩展规模，模型还有多大的性能提升空间？\n韦福如：\n我觉得关键是如何评估。现在大多数常见问题，模型已经做得很好了，性能提升很难被直观感知。真正能拉开差距的，是那些更难、更长尾的任务，但这又涉及成本和投入产出比。从实践来看，规模化依然是提升泛化能力最有效的方式，模型也必须跨过某个能力阈值，才能真正好用。\n图片\n向大脑学习：记忆、神经可塑性与持续学习\n主 持人：除了数据和评测，还有哪些值得探索的新方向？\n韦福如：\n创新当然是必须的，但关键不是“能不能创新”，而在于“值不值得创新”。单纯把模型做大是不够的，如果把“怎么做大”和“做大”结合起来，才是真正有效的创新，也就是我们所说的科学规模化。\n判断一个创新是否有必要，前提一定是有真实问题要解决，而且要带来质的变化：一方面，它要能做以前做不了的事情；另一方面，原来能做好的事情还能继续维持，这是一个向下兼容、帕雷托提升的问题。如果只是1%或5%的改进，从工程角度可能有意义，但从科学范式上看价值有限，甚至得不偿失。从这个角度看，Transformer 依然非常强大，很多改良已经能缓解长序列、计算复杂度等问题。真正困难的不是提出新结构，而是证明你的创新“非做不可”。\n人类大脑是 AI 很重要的参考对象，我们不一定要照着它实现，但它在方向和原则上具有启发意义。Transformer 的价值就在于提供了一个统一结构，让语言、视觉、语音可以共享同一套范式。接下来，比如神经可塑性（neuroplasticity）和预测性处理（predictive processing）都将是 AI 最重要的研究课题和目标。\n下一步真正重要的方向，我认为是持续学习和在线学习。AI 在“记忆”上已经很强了，这一点和规模化密切相关，但在“学习”上还远远不如人。模型训练完成之后基本就定型了，无法像人类一样在新的环境和任务中不断成长。因此，最终的解法未必是单点的架构创新，而更可能是系统层面、甚至产品层面的创新。不一定非要改 Transformer，只要整个系统具备持续学习的能力就可以了。\n至于规划、搜索、MoE 这些方向，在现有技术框架下其实都有相对清晰的实现路径，MoE 在效率上的进展也已经相当成熟，这和大脑只激活少量神经元的机制是相通的。\n总体来说，创新方向很多，但真正困难的是做“有意义的创新”。没有必要性的创新，往往不是在解决问题，而是在制造新的问题。\n图片\n模型架构、系统与硬件的协同进化\n主持人：你们团队在模型架构创新、低比特量化、合成数据等方面有很多新的尝试。请具体介绍一下你们最近在这些方向上有的新发现或突破。\n韦福如：\n我们在做的是全栈、端到端、系统性的 AI 研究，围绕第一性原理，从模型架构、学习范式、多模态、训练到数据和系统一体化推进，重点专注于范式迁移的技术创新和下一代 AI 模型的构建。站在更高层面看，现在 AI 的核心目标其实只有两件事：一是智能的边界，二是智能效能，而效能已经从单纯的成本问题，演变成了能源和物理约束的问题。\n\n从技术结构上看，AI 最终无非是模型架构、学习机制、数据，以及更底层的系统和硬件协同。Transformer 的成功，本身就是算法与系统协同创新的结果，它依赖 GPU 并行和 self-attention （自注意力机制）的高效实现。我们在模型架构上持续探索，包括 DeepNet、LongNet、\nBitNet 、 YOCO 、 Differential Transformer\n等，在 Transformer 的基础上寻找下一个必须解决的问题。比如 1-bit LLMs，把计算从浮点数的矩阵乘法改为加法，在能效和能源层面将有机会带来根本性改变，但这也必然需要模型架构、系统和硬件的协同创新。\n在多模态方向，我们关注的核心问题是如何统一离散和连续数据的建模与学习。从早期\nBEiT\n到 LatentLM，本质都是在探索原生全模态模型的基础框架。这不仅关系到多模态生成和理解的统一，也关系到语言模型与扩散模型的融合，也就是我们所说的“大统一”逻辑的底层支撑之一，也是未来视频生成、世界模型和具身智能的一个重要基石。从产品和交互的角度看，原生多模态加上记忆，才可能构成未来 AI 的终极 UX，让 AI 在任意场景中自然地理解和利用上下文。\n还有一个是多智能体，未来的 AI 一定是多个智能体有机协作的，就像人类社会和组织一样。我们最近的工作比如 Agentic Organization 和异步思考机制就是在这个方向上非常有意思的一些探索。\n\nAI 模型的三块基石，模型架构、学习范式，以及规模化。真正决定未来上界的，其实还是学习本身。现在 AI 很大程度上混淆了记忆能力和学习能力，虽然模型在“记”上已经很强了，但在持续学习、在线学习上仍然远不如人。我们认为，未来算力的规模化会越来越多地用在强化学习上，尤其是前训练阶段的 RL Scaling，这对提升泛化和智能上界至关重要。在这个方面我们有一个工作就是 RPT。未来，AI 可能需要从单一的 Scaling Law，走向我称之为 “Experience Law” 的新范式，通过经验积累不断提升效率和能力。\n世界模型也是一个被高度关注但容易被误解的方向。在我看来，世界模型的思考能力比模拟能力更重要。世界模型更核心的作用，是作为世界验证器和奖励模型，支撑多模态思考、预测和决策，这与预测性处理、在线强化学习和神经可塑性高度相关，最终也会与大模型本身融合，而不是成为一个外接模块。\n整体来看，剩下的关键问题其实已经不多了，都会收敛到少数几个本质点：学习范式、持续学习、多模态思考以及智能体系统。真正有价值的创新，往往不是追逐热点，而是从第一性原理出发，解决那些非解不可的问题。对工业界而言，研究、模型和产品本质上是一体三面——最好的研究，才能孕育真正具有长期价值和差异化的模型，也才能最终催生具有变革意义的 AI 产品。\n图片\n通用模型 vs 垂直定制：如何做出正确选择？\n主持人：除了继续做大模型或改变架构，近几年关于高效模型、“小而美”模型以及面向垂直领域的定制化研究越来越多。你觉得这是不是一条更有潜力的路径？在通用大模型和小型、精炼模型之间，应该如何取舍？\n韦福如：\n“小”本身是一个相对的概念，没有绝对的尺度。五年前一亿参数算小，现在一百亿、甚至千亿规模的 MoE 也常被称为小模型，所以不要被大小这个表象迷惑。真正有价值的“小而美”，不是单纯变小，而是那种不平凡的一小步创新——简洁、通用、优美、直击本质，能够真正解决问题，和规模化是相辅相成的。\n从现实应用来看，大模型更多承担的是推高智能上界的角色，而在泛化学习这个核心问题被彻底解决之前，规模化仍然是唯一被证明有效的路径。模型在实际使用中必须跨过某个能力阈值，才能真正“好用”。而且，没有大就没有小，现在被广泛使用的小模型，本质上几乎都是从大模型蒸馏或迁移出来的。\n至于垂直领域，并不是每个任务都需要重新训练一个“万能模型”。关键还是必要性：当你拥有大量无法公开、也无法纳入通用模型训练的数据时，定制就非常有意义；反之，如果领域知识本身已经是通用知识，定制的价值就相对有限。需要强调的是，这里的定制是一个系统问题，往往不是定制基础模型，而是定制领域智能体，可以通过 RAG、微调，甚至更理想的“记忆”机制来实现，并尽量避免频繁更新模型参数。\n无论是小模型还是垂直模型，它们的前提始终是有一个足够强的通用模型作为底座。专有能力和通用能力在技术上并不矛盾，而是在通用能力之上优化目标的选择问题。很多时候，与其刷榜，不如把原本分布外（Out-of-Distribution）的问题，通过定制化变成分布内（In-Distribution）的问题，从而真正解决业务和场景需求。\n从这个意义上说，AI 的发展路径其实和人类教育很像：先通过大规模通用学习打好基础，再在此之上发展专业能力。目标是一致的，实现方式不必完全相同。就像造飞机不需要真的造一只鸟，但“飞”这个目标，本身正是从自然中得到的启发。\n图片\n第二增长曲线，仍在继续\n主持人：你之前提出过“人工智能基础创新的第二增长曲线”，现在回头看，这条曲线是不是已经出现了一些新的变化或拐点？\n韦福如：\n我觉得是肯定的。任何技术的发展本质上都是一条 S 曲线，这是一个物理规律，但你可以通过技术手段去延长快速上升的区间，甚至画出新的曲线。我们在 2023 年提出 “第二增长曲线”\n的时候，基于的是当时的 Scaling Law、数据和算力条件。过去一两年里，无论是在架构、数据还是计算效率上，都出现了数量级的提升，某种意义上，Scaling 曲线本身已经发生了变化。\n另一方面，AI 从来就不只有一条 S 曲线。我们已经看到预训练 Scaling、后训练 Scaling、Test-Time Scaling，再到强化学习带来的 Scaling，以及现在逐渐显现的上下文和记忆 Scaling。这中间还会有新的机会，比如像 RPT 这样的“中期训练”范式，本身就可以形成一条新的曲线。当你不断切换和叠加不同的 Scaling 维度，整体能力就还能继续向上发展。\n从本质上看，AI 的进步高度依赖于是否找对了 Scaling 的方向，也就是如何更高效地把算力和电能转化为智能。接下来，我认为至少有两个新的 Scaling Law 值得关注：一个是 Agentic Scaling Law，关注智能体在复杂环境中连续工作时长或执行步数与算力之间的关系，这对 AI 的真实应用和商业化至关重要；另一个是 Experience Law，也可以理解为 Runtime Scaling（运行时规模化），AI 通过运行和经验积累，在性能和效率上持续提升，这与在线学习密切相关，也直接关系到智能上界。\n主持人：\n今天我们就先讨论到这里，感谢韦福如博士的精彩分享。我们下期节目再见！\n声明：\n《AI Next》是微软亚洲研究院推出的一档利用 AI 技术制作的播客，旨在探索合成生成式技术在内容制作和传播中的新形式与可能性。节目中的语音均非真人录制，而是由研究技术原型合成。其中，嘉宾语音由 VibeVoice 技术基于既定文字内容以及嘉宾声音样本合成，宣传视频中的嘉宾人物头像由 VASA 技术基于音频内容以及卡通风格合成和渲染。\n作为一项探索性播客节目，《AI Next》中涉及的相关技术仍处于研究阶段，生成内容的表现可能受多种输入因素的影响。节目制作及发布遵循人工智能、数据安全与隐私保护相关的法律法规。节目中所使用的语音、文字与图像均获得嘉宾授权，仅用于科研与科普展示。微软亚洲研究院将持续对相关技术进行优化，提升节目的收听体验。\n随着人工智能技术的快速发展，确保相关技术能被人们信赖是一个亟需解决的问题。微软主动采取了一系列措施来预判和降低人工智能技术所带来的风险。微软致力于依照以人为本的伦理原则推动人工智能的发展，早在2018年就发布了“公平、包容、可靠与安全、透明、隐私与保障、负责”六个负责任的人工智能原则（Responsible AI Principles），随后又发布了负责任的人工智能标准（Responsible AI Standards）将各项原则实施落地，并设置了治理架构确保各团队把各项原则和标准落实到日常工作中。微软也持续与全球的研究人员和学术机构合作，不断推进负责任的人工智能的实践和技术。\n所有使用或转载本节目的个人与机构，在引用与传播时需明确标注相关内容“由AI技术合成”或者不得移除已有的标识，并避免任何可能引发误导或侵犯他人权益的使用方式。若您发现本节目内容或相关技术被非法使用，请通过微软安全响应中心（Microsoft Security Response Center）网站进行举报："
    }
  },
  {
    "id": "235162645922741249",
    "type": "industryBusiness",
    "url": "https://www.microsoft.com/en-us/security/blog/2026/01/14/microsoft-named-a-leader-in-idc-marketscape-for-unified-ai-governance-platforms/",
    "title": "微软被评为IDC MarketScape统一AI治理平台领导者",
    "description": "微软因提供统一、端到端的AI治理平台，集成责任AI原则与安全功能，被IDC评为行业领导者。",
    "published_date": "2026-01-14T17:00:00.008Z",
    "authors": "Herain Oberoi and Don Scott",
    "source": "微软云",
    "score": 78,
    "category": "AI产品",
    "tags": [
      "AI治理",
      "微软",
      "责任AI",
      "AI安全",
      "合规"
    ],
    "details": {
      "content_html": "<p>As organizations rapidly embrace generative and agentic AI, ensuring robust, unified governance has never been more critical. That’s why Microsoft is honored to be named a Leader in the 2025-2026 IDC MarketScape for Worldwide Unified AI Governance Platforms (Vendor Assessment (#US53514825, December 2025). We believe this recognition highlights our commitment to making AI innovation safe, responsible, and enterprise-ready—so you can move fast without compromising trust or compliance.</p>\n\n\n\n<p>Read the IDC MarketScape for Unified AI Governance Platforms report<br>A graphic showing Microsoft’s position in the Leaders section of the IDC report.<br>Figure 1. IDC MarketScape vendor analysis model is designed to provide an overview of the competitive fitness of technology and suppliers in a given market. The research methodology utilizes a rigorous scoring methodology based on both qualitative and quantitative criteria that results in a single graphical illustration of each supplier’s position within a given market. The Capabilities score measures supplier product, go-to-market and business execution in the short term. The Strategy score measures alignment of supplier strategies with customer requirements in a three- to five-year timeframe. Supplier market share is represented by the size of the icons.<br>The urgency for a unified AI governance strategy is being driven by stricter regulatory demands, the sheer complexity of managing AI systems across multiple AI platforms and multicloud and hybrid environments, and leadership concerns for risk related to negative brand impact. Centralized, end-to-end governance platforms help organizations reduce compliance bottlenecks, lower operational risks, and turn governance into a strategic driver for responsible AI innovation. In today’s landscape, unified AI governance is not just a compliance obligation—it is critical infrastructure for trust, transparency, and sustainable business transformation.</p>\n\n\n\n<p>Our own approach to AI is anchored to Microsoft’s Responsible AI standard, backed by a dedicated Office of Responsible AI. Drawing from our internal experience in building, securing, and governing AI systems, we translate these learnings directly into our AI management tools and security platform. As a result, customers benefit from features such as transparency notes, fairness analysis, explainability tools, safety guardrails, regulatory compliance assessments, agent identity, data security, vulnerability identification, and protection against cyberthreats like prompt-injection attacks. These tools enable them to develop, secure, and govern AI that aligns with ethical principles and is built to help support compliance with regulatory requirements. By integrating these capabilities, we empower organizations to make ethical decisions and safeguard their business processes throughout the entire AI lifecycle.</p>\n\n\n\n<p>Microsoft’s AI Governance capabilities aim to provide integrated and centralized control for observability, management, and security across IT, developer, and security teams, ensuring integrated governance within their existing tools. Microsoft Foundry acts as our main control point for model development, evaluation, deployment, and monitoring, featuring a curated model catalog, machine learning oeprations, robust evaluation, and embedded content safety guardrails. Microsoft Agent 365, which was not yet available at the time of the IDC publication, provides a centralized control plane for IT, helping teams confidently deploy, manage, and secure their agentic AI published through Microsoft 365 Copilot, Microsoft Copilot Studio, and Microsoft Foundry.</p>\n\n\n\n<p>Deeply embedded security systems are integral to Microsoft’s AI governance solution. Integrations with Microsoft Purview provide real-time data security, compliance, and governance tools, while Microsoft Entra provides agent identity and controls to manage agent sprawl and prevent unauthorized access to confidential resources. Microsoft Defender offers AI-specific posture management, threat detection, and runtime protection. Microsoft Purview Compliance Manager automates adherence to more than 100 regulatory frameworks. Granular audit logging and automated documentation bolster regulatory and forensic capabilities, enabling organizations in regulated industries to innovate with AI while maintaining oversight, secure collaboration, and consistent policy enforcement.</p>\n\n\n\n<p>Guidance for security and governance leaders and CISOs<br>To empower organizations in advancing their AI transformation initiatives, it is crucial to focus on the following priorities for establishing a secure, well-governed, and scalable AI framework. The guidance below provides Microsoft’s recommendations for fulfilling these best practices:</p>\n\n\n\n<p>CISO guidance What it means How Microsoft delivers<br>Adopt a unified, end‑to‑end governance platform Establish a comprehensive, integrated governance system covering traditional machine learning, generative AI, and agentic AI. Ensure unified oversight from development through deployment and monitoring. Microsoft enables observability and governance at every layer across IT, developer, and security teams to provide an integrated and cohesive governance platform that enables teams to play their part from within the tools they use. Microsoft Foundry acts as the developer control plane, connecting model development, evaluation, security controls, and continuous monitoring. Microsoft Agent 365 is the control plane for IT, enabling discovery, security, deployment, and observability for agentic AI in the enterprise. Microsoft Purview, Entra, and Defender integrate to deliver consistent full-stack governance across data, identity, threat protection, and compliance.<br>Industry‑leading responsible AI infrastructure Implement responsible AI practices as a foundational part of engineering and operations, with transparency and fairness built in. Microsoft embeds its Responsible AI Standards into our engineering processes, supported by the Office of Responsible AI. Automatic generation of model cards and built-in fairness mechanisms set Microsoft apart as a strategic differentiator, pairing technical controls with mature governance processes. Microsoft’s Responsible AI Transparency Report provides visibility to how we develop and deploy AI models and systems responsibility and provides a model for customers to emulate our best practices.<br>Advanced security and real‑time protection Provide robust, real-time defense against emerging AI security threats, especially for regulated industries. Microsoft’s platform features real-time jailbreak detection, encrypted agent-to-agent communication, tamper-evident audit logs for model and agent actions, and deep integration with Defender to provide AI-specific threat detection, security posture management, and automated incident response capabilities. These capabilities are especially critical for regulated sectors.<br>Automated compliance at scale Automate compliance processes, enable policy enforcement throughout the AI lifecycle, and support audit readiness across hybrid and multicloud environments. Microsoft Purview streamlines compliance adherence for regulatory requirements and provides comprehensive support for hybrid and multicloud deployments—giving customers repeatable and auditable governance processes.<br>We believe we are differentiated in the AI governance space by delivering a unified, end-to-end platform that embeds responsible AI principles and robust security at every layer—from agents and applications to underlying infrastructure. Through native integration of Microsoft Foundry, Microsoft Agent 365, Purview, Entra, and Defender, organizations benefit from centralized oversight and observability across the layers of the organization with consistent protection and operationalized compliance across the AI lifecycle. Our comprehensive approach removes disparate and disconnected tooling, enabling organizations to build trustworthy, transparent, and secure AI solutions that can start secure and stay secure. We believe this approach uniquely differentiates Microsoft as a leader in operationalizing responsible, secure, and auditable AI at scale.</p>\n\n\n\n<p>Strengthen your security strategy with Microsoft AI governance solutions<br>Agentic and generative AI are reshaping business processes, creating a new frontier for security and governance. Organizations that act early and prioritize governance best practices—unified governance platforms, build-in responsible AI tooling, and integrated security—will be best positioned to innovate confidently and maintain trust.</p>\n\n\n\n<p>Microsoft approaches AI governance with a commitment to embedding responsible practices and robust security at every layer of the AI ecosystem. Our AI governance and security solutions empower customers with built-in transparency, fairness, and compliance tools throughout engineering and operations. We believe this approach allows organizations to benefit from centralized oversight, enforce policies consistently across the entire AI lifecycle, and achieve audit readiness—even in the rapidly changing landscape of generative and agentic AI.</p>\n\n\n\n<p>Explore more<br>Read the IDC MarketScape excerpt.<br>Learn more about AI Security, Governance and Compliance.<br>Read our latest Security for AI blog to learn more about our latest capabilities<br>To learn more about Microsoft Security solutions, visit our website. Bookmark the Security blog to keep up with our expert coverage on security matters. Also, follow us on LinkedIn (Microsoft Security) and X (@MSFTSecurity) for the latest news and updates on cybersecurity.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/security/blog/2026/01/14/microsoft-named-a-leader-in-idc-marketscape-for-unified-ai-governance-platforms/\" target=\"_blank\">Microsoft named a Leader in IDC MarketScape for Unified AI Governance Platforms</a> appeared first on <a href=\"https://azure.microsoft.com/en-us/blog\" target=\"_blank\">Microsoft Azure Blog</a>.</p>"
    }
  }
]